{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Uber Eats categories' links"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "from urllib.error import URLError\n",
    "import time\n",
    "import requests\n",
    "HEADERS =                 {\n",
    "                    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
    "                                  '(KHTML, like Gecko) Chrome/102.0.5005.63 Safari/537.36',\n",
    "                }\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requesting url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.ubereats.com/gb/category/london-eng'\n",
    "url = requests.get(url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating beautiful soup object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating beautiful soup object\n",
    "soup = BeautifulSoup(url.content, 'html.parser')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a list of all category links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find category elements\n",
    "cat_urls = soup.find_all('main', class_='dr')\n",
    "cat_urls_list = []\n",
    "\n",
    "#extract link of each category and append it to a list \"cat_urls_list\"\n",
    "for ind_cat in cat_urls:\n",
    "    for link in ind_cat.find_all('a', href=True):\n",
    "        href = link['href']\n",
    "        cat_urls_list.append('https://www.ubereats.com'+href)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function for getting the amount of restaurants in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_rest_urls_list = []\n",
    "\n",
    "def get_category_rests(category_url, HEADERS):\n",
    "    req = Request(category_url, headers=HEADERS)\n",
    "    webpage = urlopen(req, timeout=10).read()\n",
    "    rest_soup = BeautifulSoup(webpage, 'html.parser')\n",
    "    cat_rest_urls = rest_soup.find_all(\"div\", class_= \"ak cx\") \n",
    "    for ind_url in cat_rest_urls:\n",
    "        for url in ind_url.find_all('a', href=True):\n",
    "            href = url['href']\n",
    "            cat_rest_urls_list.append(href)\n",
    "    return cat_rest_urls_list\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying function to the urls of my list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary to store the results\n",
    "category_rests_dict = {}\n",
    "\n",
    "# Loop through the category urls and call the modified function\n",
    "for i in cat_urls_list:\n",
    "    category_rest_urls_list = get_category_rests(i, HEADERS)\n",
    "    #Get the number of restaurants in each category\n",
    "    category_rests_dict[i] = len(category_rest_urls_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of category names starting from the url list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split links and store what is after last \"/\"\n",
    "london_cat_all = [url.split('/')[-1] for url in cat_urls_list]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the complete dictionary into a dataframe and store it as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "london_num_rest_cat = pd.DataFrame.from_dict(category_rests_dict, orient='index', columns=['rest_num'])\n",
    "london_num_rest_cat.index.name = 'url'\n",
    "\n",
    "#add the list containing categories names as a new column in the dataframe\n",
    "london_num_rest_cat['category'] = london_cat_all\n",
    "\n",
    "#save as csv\n",
    "london_num_rest_cat.to_csv('../scraped-data/test/1-London-cat-all.csv', index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have a dataset containing the categories for London, the respective links and the amount of restaurants inside each one. Now, lets get the urls of all restaurants inside each category. Move to the \"London-restaurant-urls\" notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
